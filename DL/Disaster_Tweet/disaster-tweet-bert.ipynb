{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceType":"competition","sourceId":17777,"databundleVersionId":869809},{"sourceType":"modelInstanceVersion","sourceId":6068,"databundleVersionId":7429247,"modelInstanceId":4689}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Problem Description \nTwitter has become an important communication channel in times of emergency.\nThe ubiquitousness of smartphones enables people to announce an emergency they’re observing in real-time. Because of this, more agencies are interested in programatically monitoring Twitter (i.e. disaster relief organizations and news agencies).","metadata":{}},{"cell_type":"code","source":"pip install torch transformers","metadata":{"execution":{"iopub.status.busy":"2024-02-19T16:47:14.243027Z","iopub.execute_input":"2024-02-19T16:47:14.243408Z","iopub.status.idle":"2024-02-19T16:47:27.346712Z","shell.execute_reply.started":"2024-02-19T16:47:14.243352Z","shell.execute_reply":"2024-02-19T16:47:27.345468Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.1.2)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.37.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2023.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.3)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.24.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.1)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.2)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.11.17)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Load required libraries ","metadata":{}},{"cell_type":"code","source":"import pandas as pd \nfrom sklearn.model_selection import train_test_split \n\nfrom transformers import BertTokenizer, TFBertForSequenceClassification, BertConfig, AdamW, get_linear_schedule_with_warmup\nfrom tensorflow.keras.optimizers import Adam\n\nfrom tensorflow.keras.callbacks import EarlyStopping","metadata":{"execution":{"iopub.status.busy":"2024-02-19T16:52:37.514844Z","iopub.execute_input":"2024-02-19T16:52:37.515214Z","iopub.status.idle":"2024-02-19T16:52:37.520785Z","shell.execute_reply.started":"2024-02-19T16:52:37.515182Z","shell.execute_reply":"2024-02-19T16:52:37.519841Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"# Load the data","metadata":{}},{"cell_type":"code","source":"train_dataset = pd.read_csv('/kaggle/input/nlp-getting-started/train.csv')\ntest_dataset = pd.read_csv('/kaggle/input/nlp-getting-started/test.csv')","metadata":{"execution":{"iopub.status.busy":"2024-02-19T16:47:49.821486Z","iopub.execute_input":"2024-02-19T16:47:49.822471Z","iopub.status.idle":"2024-02-19T16:47:49.896778Z","shell.execute_reply.started":"2024-02-19T16:47:49.822419Z","shell.execute_reply":"2024-02-19T16:47:49.895975Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# EDA\n* id - a unique identifier for each tweet\n* text - the text of the tweet\n* location - the location the tweet was sent from (may be blank)\n* keyword - a particular keyword from the tweet (may be blank)\n* target - in train.csv only, this denotes whether a tweet is about a real disaster (1) or not (0)","metadata":{}},{"cell_type":"code","source":"train_dataset.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-19T17:08:11.264094Z","iopub.execute_input":"2024-02-19T17:08:11.264504Z","iopub.status.idle":"2024-02-19T17:08:11.280456Z","shell.execute_reply.started":"2024-02-19T17:08:11.264467Z","shell.execute_reply":"2024-02-19T17:08:11.279466Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"   id keyword location                                               text  \\\n0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n\n   target  \n0       1  \n1       1  \n2       1  \n3       1  \n4       1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Our Deeds are the Reason of this #earthquake M...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Forest fire near La Ronge Sask. Canada</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>All residents asked to 'shelter in place' are ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>13,000 people receive #wildfires evacuation or...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_dataset.info()","metadata":{"execution":{"iopub.status.busy":"2024-02-19T16:47:52.470303Z","iopub.execute_input":"2024-02-19T16:47:52.470695Z","iopub.status.idle":"2024-02-19T16:47:52.500440Z","shell.execute_reply.started":"2024-02-19T16:47:52.470666Z","shell.execute_reply":"2024-02-19T16:47:52.499336Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 7613 entries, 0 to 7612\nData columns (total 5 columns):\n #   Column    Non-Null Count  Dtype \n---  ------    --------------  ----- \n 0   id        7613 non-null   int64 \n 1   keyword   7552 non-null   object\n 2   location  5080 non-null   object\n 3   text      7613 non-null   object\n 4   target    7613 non-null   int64 \ndtypes: int64(2), object(3)\nmemory usage: 297.5+ KB\n","output_type":"stream"}]},{"cell_type":"code","source":"test_dataset.info()","metadata":{"execution":{"iopub.status.busy":"2024-02-19T16:47:56.919800Z","iopub.execute_input":"2024-02-19T16:47:56.920419Z","iopub.status.idle":"2024-02-19T16:47:56.930732Z","shell.execute_reply.started":"2024-02-19T16:47:56.920360Z","shell.execute_reply":"2024-02-19T16:47:56.929827Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 3263 entries, 0 to 3262\nData columns (total 4 columns):\n #   Column    Non-Null Count  Dtype \n---  ------    --------------  ----- \n 0   id        3263 non-null   int64 \n 1   keyword   3237 non-null   object\n 2   location  2158 non-null   object\n 3   text      3263 non-null   object\ndtypes: int64(1), object(3)\nmemory usage: 102.1+ KB\n","output_type":"stream"}]},{"cell_type":"markdown","source":"*Notice here that this is a imbalanced dataset so we need to do the stratified sampling afterwards* ","metadata":{}},{"cell_type":"code","source":"train_dataset['target'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-02-19T16:47:59.489524Z","iopub.execute_input":"2024-02-19T16:47:59.490086Z","iopub.status.idle":"2024-02-19T16:47:59.523742Z","shell.execute_reply.started":"2024-02-19T16:47:59.490041Z","shell.execute_reply":"2024-02-19T16:47:59.522523Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"target\n0    4342\n1    3271\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"# Prepare the Data ","metadata":{}},{"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(\n    train_dataset['text'],  # Text data\n    train_dataset['target'],  # Corresponding labels\n    test_size=0.2,  # 20% of the data for validation\n    random_state=42,  # Seed for reproducibility\n    stratify=train_dataset['target']  # Stratify by the target variable to maintain class balance\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-19T16:48:03.650248Z","iopub.execute_input":"2024-02-19T16:48:03.650893Z","iopub.status.idle":"2024-02-19T16:48:03.662322Z","shell.execute_reply.started":"2024-02-19T16:48:03.650859Z","shell.execute_reply":"2024-02-19T16:48:03.661599Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"print(len(X_train), len(y_train))\nprint(len(X_val), len(y_val))","metadata":{"execution":{"iopub.status.busy":"2024-02-19T16:48:06.087455Z","iopub.execute_input":"2024-02-19T16:48:06.087798Z","iopub.status.idle":"2024-02-19T16:48:06.092960Z","shell.execute_reply.started":"2024-02-19T16:48:06.087773Z","shell.execute_reply":"2024-02-19T16:48:06.091969Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"6090 6090\n1523 1523\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Load pre-trained tokenizer and tokenize the dataset","metadata":{}},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n\ntrain_encodings = tokenizer(X_train.tolist(), truncation=True, padding=True, max_length=128)\nval_encodings = tokenizer(X_val.tolist(), truncation=True, padding=True, max_length=128)","metadata":{"execution":{"iopub.status.busy":"2024-02-19T15:59:26.994048Z","iopub.execute_input":"2024-02-19T15:59:26.994786Z","iopub.status.idle":"2024-02-19T15:59:34.193977Z","shell.execute_reply.started":"2024-02-19T15:59:26.994755Z","shell.execute_reply":"2024-02-19T15:59:34.192963Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3fd6badca644752ba48a3413c2e800f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9da6b2ec059440768bb7b6e5d4a6ccd0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8ff7c23748d4ec7975ab2324562a0b5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"785d0c21007d44bcbc5ab2ac1c143694"}},"metadata":{}}]},{"cell_type":"code","source":"import keras_nlp\n\n# Load a DistilBERT model.\npreset= \"distil_bert_base_en_uncased\"\n\n# Use a shorter sequence length.\npreprocessor = keras_nlp.models.DistilBertPreprocessor.from_preset(preset,\n                                                                   sequence_length=160,\n                                                                   name=\"preprocessor_4_tweets\"\n                                                                  )\n\n# Pretrained classifier.\nclassifier = keras_nlp.models.DistilBertClassifier.from_preset(preset,\n                                                               preprocessor = preprocessor, \n                                                               num_classes=2)\n\nclassifier.summary()","metadata":{"execution":{"iopub.status.busy":"2024-02-19T16:48:11.434084Z","iopub.execute_input":"2024-02-19T16:48:11.435056Z","iopub.status.idle":"2024-02-19T16:48:38.000074Z","shell.execute_reply.started":"2024-02-19T16:48:11.435011Z","shell.execute_reply":"2024-02-19T16:48:37.999217Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"2024-02-19 16:48:13.161439: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-02-19 16:48:13.161533: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-02-19 16:48:13.287102: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Using TensorFlow backend\n","output_type":"stream"},{"name":"stderr","text":"Attaching 'tokenizer.json' from model 'keras/distil_bert/keras/distil_bert_base_en_uncased/2' to your Kaggle notebook...\nAttaching 'tokenizer.json' from model 'keras/distil_bert/keras/distil_bert_base_en_uncased/2' to your Kaggle notebook...\nAttaching 'assets/tokenizer/vocabulary.txt' from model 'keras/distil_bert/keras/distil_bert_base_en_uncased/2' to your Kaggle notebook...\nAttaching 'config.json' from model 'keras/distil_bert/keras/distil_bert_base_en_uncased/2' to your Kaggle notebook...\nAttaching 'config.json' from model 'keras/distil_bert/keras/distil_bert_base_en_uncased/2' to your Kaggle notebook...\nAttaching 'model.weights.h5' from model 'keras/distil_bert/keras/distil_bert_base_en_uncased/2' to your Kaggle notebook...\n/opt/conda/lib/python3.10/site-packages/keras_nlp/src/models/backbone.py:37: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n  return id(getattr(self, attr)) not in self._functional_layer_ids\n/opt/conda/lib/python3.10/site-packages/keras_nlp/src/models/backbone.py:37: UserWarning: `layer.updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n  return id(getattr(self, attr)) not in self._functional_layer_ids\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mPreprocessor: \"preprocessor_4_tweets\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"preprocessor_4_tweets\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mTokenizer (type)                                  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                            Vocab #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ distil_bert_tokenizer (\u001b[38;5;33mDistilBertTokenizer\u001b[0m)        │                                              \u001b[38;5;34m30,522\u001b[0m │\n└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Tokenizer (type)                                   </span>┃<span style=\"font-weight: bold\">                                             Vocab # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ distil_bert_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DistilBertTokenizer</span>)        │                                              <span style=\"color: #00af00; text-decoration-color: #00af00\">30,522</span> │\n└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"distil_bert_classifier\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"distil_bert_classifier\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape                          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)                           │               \u001b[38;5;34m0\u001b[0m │\n├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)                           │               \u001b[38;5;34m0\u001b[0m │\n├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n│ distil_bert_backbone (\u001b[38;5;33mDistilBertBackbone\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)                      │      \u001b[38;5;34m66,362,880\u001b[0m │\n├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n│ tf.__operators__.getitem (\u001b[38;5;33mSlicingOpLambda\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)                            │               \u001b[38;5;34m0\u001b[0m │\n├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n│ pooled_dense (\u001b[38;5;33mDense\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)                            │         \u001b[38;5;34m590,592\u001b[0m │\n├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n│ classifier_dropout (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)                            │               \u001b[38;5;34m0\u001b[0m │\n├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n│ logits (\u001b[38;5;33mDense\u001b[0m)                                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                              │           \u001b[38;5;34m1,538\u001b[0m │\n└───────────────────────────────────────────────┴────────────────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                                  </span>┃<span style=\"font-weight: bold\"> Output Shape                           </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n│ distil_bert_backbone (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DistilBertBackbone</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)                      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">66,362,880</span> │\n├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n│ tf.__operators__.getitem (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SlicingOpLambda</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)                            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n│ pooled_dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)                            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">590,592</span> │\n├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n│ classifier_dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)                            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n│ logits (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,538</span> │\n└───────────────────────────────────────────────┴────────────────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m66,955,010\u001b[0m (255.41 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">66,955,010</span> (255.41 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m66,955,010\u001b[0m (255.41 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">66,955,010</span> (255.41 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}]},{"cell_type":"markdown","source":"## Convert to Tensorflow dataset ","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\n\n\ndef create_tf_dataset(encodings, labels):\n    dataset = tf.data.Dataset.from_tensor_slices((\n        {\n            'input_ids': encodings['input_ids'],\n            'attention_mask': encodings['attention_mask']\n        },\n        labels\n    ))\n    dataset = dataset.shuffle(10000).batch(32)\n    return dataset\n\ntrain_dataset = create_tf_dataset(train_encodings, y_train)\nval_dataset = create_tf_dataset(val_encodings, y_val)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-19T15:13:57.084567Z","iopub.execute_input":"2024-02-19T15:13:57.085358Z","iopub.status.idle":"2024-02-19T15:14:01.298064Z","shell.execute_reply.started":"2024-02-19T15:13:57.085325Z","shell.execute_reply":"2024-02-19T15:14:01.297295Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## Create PyTorch Datasets","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\n\nclass TextDataset(Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx], dtype=torch.long) for key, val in self.encodings.items()}\n        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n        return item\n\n    def __len__(self):\n        return len(self.labels)\n\n# Convert the lists to tensors before creating datasets if not already tensors\ny_train_tensor = torch.tensor(y_train.to_numpy(), dtype=torch.long)\ny_val_tensor = torch.tensor(y_val.to_numpy(), dtype=torch.long)\n\n# Create PyTorch datasets\ntrain_dataset = TextDataset(train_encodings, y_train_tensor)\nval_dataset = TextDataset(val_encodings, y_val_tensor)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-19T16:24:23.961088Z","iopub.execute_input":"2024-02-19T16:24:23.961972Z","iopub.status.idle":"2024-02-19T16:24:23.974380Z","shell.execute_reply.started":"2024-02-19T16:24:23.961929Z","shell.execute_reply":"2024-02-19T16:24:23.973437Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"# Configure the model for training ","metadata":{}},{"cell_type":"code","source":"config = BertConfig.from_pretrained('bert-base-uncased', hidden_dropout_prob=0.5, attention_probs_dropout_prob=0.5)\n\nmodel = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', config=config)\n\noptimizer = Adam(learning_rate=5e-5)\nloss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\nmetric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n\nmodel.compile(optimizer=optimizer, loss=loss, metrics=[metric])","metadata":{"execution":{"iopub.status.busy":"2024-02-19T15:51:04.957915Z","iopub.execute_input":"2024-02-19T15:51:04.958490Z","iopub.status.idle":"2024-02-19T15:51:07.598643Z","shell.execute_reply.started":"2024-02-19T15:51:04.958457Z","shell.execute_reply":"2024-02-19T15:51:07.597917Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n\nSome weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import BertForSequenceClassification, AdamW\n\nmodel = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n\nfrom transformers import get_linear_schedule_with_warmup\nimport torch\n\noptimizer = AdamW(model.parameters(), lr=5e-5)\n\nepochs = 4\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=32)\n\ntotal_steps = len(train_loader) * epochs\n\nscheduler = get_linear_schedule_with_warmup(optimizer, \n                                            num_warmup_steps=0, # Default value\n                                            num_training_steps=total_steps)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-19T16:24:28.536385Z","iopub.execute_input":"2024-02-19T16:24:28.537250Z","iopub.status.idle":"2024-02-19T16:24:29.058528Z","shell.execute_reply.started":"2024-02-19T16:24:28.537216Z","shell.execute_reply":"2024-02-19T16:24:29.057642Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"for batch in train_loader:\n    print({key: val.shape for key, val in batch.items()})","metadata":{"execution":{"iopub.status.busy":"2024-02-19T16:24:46.187944Z","iopub.execute_input":"2024-02-19T16:24:46.188644Z","iopub.status.idle":"2024-02-19T16:24:46.678559Z","shell.execute_reply.started":"2024-02-19T16:24:46.188610Z","shell.execute_reply":"2024-02-19T16:24:46.677616Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_34/1301762782.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n","output_type":"stream"},{"name":"stdout","text":"{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([32, 84]), 'token_type_ids': torch.Size([32, 84]), 'attention_mask': torch.Size([32, 84]), 'labels': torch.Size([32])}\n{'input_ids': torch.Size([10, 84]), 'token_type_ids': torch.Size([10, 84]), 'attention_mask': torch.Size([10, 84]), 'labels': torch.Size([10])}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Train the Model ","metadata":{}},{"cell_type":"code","source":"early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n\nhistory = model.fit(\n    train_dataset,\n    validation_data=val_dataset,\n    epochs=10,\n    callbacks=[early_stopping]\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-19T15:35:14.825821Z","iopub.execute_input":"2024-02-19T15:35:14.826804Z","iopub.status.idle":"2024-02-19T15:39:52.533073Z","shell.execute_reply.started":"2024-02-19T15:35:14.826752Z","shell.execute_reply":"2024-02-19T15:39:52.532301Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Epoch 1/10\n191/191 [==============================] - 69s 363ms/step - loss: 0.1487 - accuracy: 0.9483 - val_loss: 0.5579 - val_accuracy: 0.8260\nEpoch 2/10\n191/191 [==============================] - 69s 364ms/step - loss: 0.1044 - accuracy: 0.9608 - val_loss: 0.5789 - val_accuracy: 0.8083\nEpoch 3/10\n191/191 [==============================] - 69s 363ms/step - loss: 0.0798 - accuracy: 0.9690 - val_loss: 0.6621 - val_accuracy: 0.8207\nEpoch 4/10\n191/191 [==============================] - 69s 363ms/step - loss: 0.0641 - accuracy: 0.9721 - val_loss: 0.8318 - val_accuracy: 0.8063\n","output_type":"stream"}]},{"cell_type":"code","source":"from tqdm import tqdm\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\nfor epoch in range(epochs):\n    model.train()\n    train_loss = 0\n    for batch in tqdm(train_loader):\n        optimizer.zero_grad()\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n        loss = outputs.loss  # Correct way to access the loss\n        train_loss += loss.item()\n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n    avg_train_loss = train_loss / len(train_loader)\n    print(f'Epoch {epoch + 1}, Train Loss: {avg_train_loss:.4f}')\n\n    # Validation step\n    model.eval()\n    val_loss = 0\n    with torch.no_grad():\n        for batch in val_loader:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['labels'].to(device)\n            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n            loss = outputs.loss  # Correct way to access the loss\n            val_loss += loss.item()\n    avg_val_loss = val_loss / len(val_loader)\n    print(f'Epoch {epoch + 1}, Validation Loss: {avg_val_loss:.4f}')\n","metadata":{"execution":{"iopub.status.busy":"2024-02-19T16:24:59.952110Z","iopub.execute_input":"2024-02-19T16:24:59.952809Z","iopub.status.idle":"2024-02-19T16:28:31.005618Z","shell.execute_reply.started":"2024-02-19T16:24:59.952780Z","shell.execute_reply":"2024-02-19T16:28:31.004633Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"  0%|          | 0/191 [00:00<?, ?it/s]/tmp/ipykernel_34/1301762782.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n100%|██████████| 191/191 [00:50<00:00,  3.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1, Train Loss: 0.4423\nEpoch 1, Validation Loss: 0.3649\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 191/191 [00:49<00:00,  3.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2, Train Loss: 0.3065\nEpoch 2, Validation Loss: 0.3932\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 191/191 [00:49<00:00,  3.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3, Train Loss: 0.1966\nEpoch 3, Validation Loss: 0.4128\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 191/191 [00:49<00:00,  3.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4, Train Loss: 0.1197\nEpoch 4, Validation Loss: 0.5369\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Keras NLP ","metadata":{}},{"cell_type":"code","source":"import keras_core as keras\n\n# Compile\nclassifier.compile(\n    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), #'binary_crossentropy',\n    #optimizer=keras.optimizers.Adam(1e-5),\n    optimizer=Adam(learning_rate=5e-5),\n    metrics= [\"accuracy\"]  \n)\nBATCH_SIZE = 32\nEPOCHS = 2\n# Fit\nhistory = classifier.fit(x=X_train,\n                         y=y_train,\n                         batch_size=BATCH_SIZE,\n                         epochs=EPOCHS, \n                         validation_data=(X_val, y_val)\n                        )","metadata":{"execution":{"iopub.status.busy":"2024-02-19T16:54:07.460250Z","iopub.execute_input":"2024-02-19T16:54:07.460623Z","iopub.status.idle":"2024-02-19T16:56:47.482371Z","shell.execute_reply.started":"2024-02-19T16:54:07.460593Z","shell.execute_reply":"2024-02-19T16:56:47.481540Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Epoch 1/2\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1708361667.400985     115 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"191/191 [==============================] - 91s 359ms/step - loss: 0.4369 - accuracy: 0.8054 - val_loss: 0.4221 - val_accuracy: 0.8168\nEpoch 2/2\n191/191 [==============================] - 64s 335ms/step - loss: 0.3096 - accuracy: 0.8808 - val_loss: 0.5212 - val_accuracy: 0.7958\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Make prediciton to the test.csv and save as submission.csv ","metadata":{}},{"cell_type":"code","source":"from transformers import BertTokenizer\n\n# Initialize the tokenizer\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n\n# Tokenize the text for prediction\ntest_encodings = tokenizer(test_dataset['text'].tolist(), truncation=True, padding=True, max_length=128, return_tensors=\"pt\")\n","metadata":{"execution":{"iopub.status.busy":"2024-02-19T16:36:24.437358Z","iopub.execute_input":"2024-02-19T16:36:24.437858Z","iopub.status.idle":"2024-02-19T16:36:27.513493Z","shell.execute_reply.started":"2024-02-19T16:36:24.437810Z","shell.execute_reply":"2024-02-19T16:36:27.512643Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"class PredictDataset(Dataset):\n    def __init__(self, encodings):\n        self.encodings = encodings\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx], dtype=torch.long) for key, val in self.encodings.items()}\n        return item\n\n    def __len__(self):\n        return len(self.encodings.input_ids)\n\n# Create a PyTorch dataset for prediction\npredict_dataset = PredictDataset(test_encodings)","metadata":{"execution":{"iopub.status.busy":"2024-02-19T16:36:36.901458Z","iopub.execute_input":"2024-02-19T16:36:36.901828Z","iopub.status.idle":"2024-02-19T16:36:36.908679Z","shell.execute_reply.started":"2024-02-19T16:36:36.901797Z","shell.execute_reply":"2024-02-19T16:36:36.907599Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\n# Prepare DataLoader\npredict_loader = DataLoader(predict_dataset, batch_size=32)\n\nmodel.eval()  # Set the model to evaluation mode\npredictions = []\n\nwith torch.no_grad():\n    for batch in predict_loader:\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        outputs = model(input_ids, attention_mask=attention_mask)\n        logits = outputs.logits\n        preds = torch.argmax(logits, dim=-1)\n        predictions.extend(preds.tolist())","metadata":{"execution":{"iopub.status.busy":"2024-02-19T16:36:38.889927Z","iopub.execute_input":"2024-02-19T16:36:38.890294Z","iopub.status.idle":"2024-02-19T16:36:46.106868Z","shell.execute_reply.started":"2024-02-19T16:36:38.890266Z","shell.execute_reply":"2024-02-19T16:36:46.106064Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_34/2292959281.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  item = {key: torch.tensor(val[idx], dtype=torch.long) for key, val in self.encodings.items()}\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\n\n# Assuming text_dataset['id'] exists and matches the order of your predictions\npredictions_df = pd.DataFrame({\n    'id': test_dataset['id'],\n    'target': predictions\n})\n\n# Save to CSV\npredictions_df.to_csv('submission_pytorch_bert.csv', index=False)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-19T16:37:03.504789Z","iopub.execute_input":"2024-02-19T16:37:03.505879Z","iopub.status.idle":"2024-02-19T16:37:03.516598Z","shell.execute_reply.started":"2024-02-19T16:37:03.505840Z","shell.execute_reply":"2024-02-19T16:37:03.515756Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"# Deliverable 2 \n## Github Repository ","metadata":{}},{"cell_type":"markdown","source":"# Deliverable 3 \n## Competition Leaderboard \n","metadata":{}}]}